# app.py
from dotenv import load_dotenv
load_dotenv()  # .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€

import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="LLMå°‚é–€å®¶Webã‚¢ãƒ—ãƒª", page_icon="ğŸ¤–", layout="centered")
st.title("ğŸ§™â€â™‚ï¸ LLMå°‚é–€å®¶Webã‚¢ãƒ—ãƒª")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€é¸æŠã—ãŸå°‚é–€å®¶ã®è¦–ç‚¹ã‹ã‚‰LLMãŒè³ªå•ã«å›ç­”ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚")
st.write("è³ªå•ã‚’å…¥åŠ›ã—ã€å°‚é–€å®¶ã‚’é¸æŠã—ã¦å›ç­”ã‚’å¾—ã¦ãã ã•ã„ã€‚")

# --- å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«å®šç¾©ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ ---
EXPERT_SYSTEM_MESSAGES = {
    "ã‚½ãƒ ãƒªã‚¨": (
        "ã‚ãªãŸã¯ä¸€æµã‚½ãƒ ãƒªã‚¨ã§ã™ã€‚æ—¥æœ¬èªã§è¦ªã—ã¿ã‚„ã™ãã€ç®‡æ¡æ›¸ãã‚’ä¸­å¿ƒã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        "å¿…ãšã€ã‚¹ã‚¿ã‚¤ãƒ«/éŠ˜æŸ„ä¾‹ã€ã€æä¾›æ¸©åº¦(â„ƒ)ã€ã€ã‚°ãƒ©ã‚¹ã€ã€ãƒšã‚¢ãƒªãƒ³ã‚°æ¡ˆã€ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"
    ),
    "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚³ãƒ¼ãƒ": (
        "ã‚ãªãŸã¯æœ‰è³‡æ ¼ã®ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ã‚³ãƒ¼ãƒå…¼æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"
        "æ—¥æœ¬èªã§ã€å®Ÿè¡Œæ‰‹é †ã‚’æ˜ç¢ºã«ã€1æ—¥ã®é£Ÿäº‹ä¾‹ãƒ»é‹å‹•ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ»ä¼‘æ¯ãƒ»æ³¨æ„ç‚¹ã‚’å…·ä½“çš„ã«æç¤ºã—ã¦ãã ã•ã„ã€‚"
    ),
    "è‹±ä¼šè©±ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼": (
        "You are a friendly English conversation tutor. Reply in simple English, "
        "add one JP note if helpful, and provide 2 alternative phrasings and 1 mini pronunciation tip."
    ),
}

# --- LLM åˆæœŸåŒ– ---
def init_llm():
    if not os.getenv("OPENAI_API_KEY"):
        st.warning("âš ï¸ OPENAI_API_KEY ãŒèª­ã¿è¾¼ã‚ã¦ã„ã¾ã›ã‚“ã€‚.env ã¾ãŸã¯ Secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    # èª²é¡Œå‘ã‘ã«è»½é‡ãƒ»é«˜å“è³ªãƒ¢ãƒ‡ãƒ«ã‚’æ—¢å®šã«
    return ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

# --- å¿…é ˆï¼šé–¢æ•°ï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼†é¸æŠå€¤â†’å›ç­”æ–‡å­—åˆ—ï¼‰ ---
def generate_response(user_text: str, role: str) -> str:
    system_msg = EXPERT_SYSTEM_MESSAGES.get(role, "")
    if not system_msg:
        return "ãƒ­ãƒ¼ãƒ«ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚EXPERT_SYSTEM_MESSAGES ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_msg),
            ("human", "{question}"),
        ]
    )
    chain = prompt | init_llm()
    try:
        result = chain.invoke({"question": user_text})
        return getattr(result, "content", str(result))
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

# --- UIï¼šãƒ­ãƒ¼ãƒ«é¸æŠï¼‹ãƒ•ã‚©ãƒ¼ãƒ  ---
role = st.radio("å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«ã‚’é¸æŠï¼š", list(EXPERT_SYSTEM_MESSAGES.keys()), horizontal=True)

with st.form("qa_form", clear_on_submit=False):
    user_text = st.text_area(
        "è³ªå•ãƒ»ç›¸è«‡å†…å®¹ï¼š",
        placeholder="ä¾‹ï¼‰é­šä»‹ã«åˆã†ã‚·ãƒ£ãƒ³ãƒ‘ãƒ¼ãƒ‹ãƒ¥ã¨æ¸©åº¦ã¯ï¼Ÿ / ä½“è„‚è‚ªã‚’è½ã¨ã™1é€±é–“ãƒ¡ãƒ‹ãƒ¥ãƒ¼ / ã“ã®è‹±æ–‡ã‚’è‡ªç„¶ã«è¨€ã„æ›ãˆã¦ ãªã©",
        height=180,
    )
    submitted = st.form_submit_button("é€ä¿¡")

if submitted:
    if not user_text.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦"):
            answer = generate_response(user_text, role)
        st.info(f"**é¸æŠãƒ­ãƒ¼ãƒ«:** {role}")
        st.write("---")
        st.subheader("å›ç­”")
        st.write(answer)

st.caption("Powered by Streamlit Ã— LangChain Ã— OpenAI")
